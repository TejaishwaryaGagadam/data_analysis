{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and mitigating age bias on credit decisions \n",
    "\n",
    "The goal of this tutorial is to introduce the basic functionality of AI Fairness 360.\n",
    "\n",
    "### Biases and Machine Learning\n",
    "A machine learning model makes predictions of an outcome for a particular instance. (Given an instance of a loan application, predict if the applicant will repay the loan.) The model makes these predictions based on a training dataset, where many other instances (other loan applications) and actual outcomes (whether they repaid) are provided. Thus, a machine learning algorithm will attempt to find patterns, or generalizations, in the training dataset to use when a prediction for a new instance is needed. (For example, one pattern it might discover is \"if a person has salary > USD 40K and has outstanding debt < USD 5, they will repay the loan\".) In many domains this technique, called supervised machine learning, has worked very well.\n",
    "\n",
    "However, sometimes the patterns that are found may not be desirable or may even be illegal. For example, a loan repay model may determine that age plays a significant role in the prediction of repayment because the training dataset happened to have better repayment for one age group than for another. This raises two problems: 1) the training dataset may not be representative of the true population of people of all age groups, and 2) even if it is representative, it is illegal to base any decision on a applicant's age, regardless of whether this is a good prediction based on historical data.\n",
    "\n",
    "AI Fairness 360 is designed to help address this problem with _fairness metrics_ and _bias mitigators_.  Fairness metrics can be used to check for bias in machine learning workflows.  Bias mitigators can be used to overcome bias in the workflow to produce a more fair outcome. \n",
    "\n",
    "The loan scenario describes an intuitive example of illegal bias. However, not all undesirable bias in machine learning is illegal it may also exist in more subtle ways.  For example, a loan company may want a diverse portfolio of customers across all income levels, and thus, will deem it undesirable if they are making more loans to high income levels over low income levels.  Although this is not illegal or unethical, it is undesirable for the company's strategy.\n",
    "\n",
    "As these two examples illustrate, a bias detection and/or mitigation toolkit needs to be tailored to the particular bias of interest.  More specifically, it needs to know the attribute or attributes, called _protected attributes_, that are of interest: race is one example of a _protected attribute_ and age is a second.\n",
    "\n",
    "### The Machine Learning Workflow\n",
    "To understand how bias can enter a machine learning model, we first review the basics of how a model is created in a supervised machine learning process.  \n",
    "\n",
    "\n",
    "\n",
    "![image](https://ibmcode-staging.us-east.containers.mybluemix.net/site-content/uploads/2018/09/aif360-1.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "First, the process starts with a _training dataset_, which contains a sequence of instances, where each instance has two components: the features and the correct prediction for those features.  Next, a machine learning algorithm is trained on this training dataset to produce a machine learning model.  This generated model can be used to make a prediction when given a new instance.  A second dataset with features and correct predictions, called a _test dataset_, is used to assess the accuracy of the model.\n",
    "Since this test dataset is the same format as the training dataset, a set of instances of features and prediction pairs, often these two datasets derive from the same initial dataset.  A random partitioning algorithm is used to split the initial dataset into training and test datasets.\n",
    "\n",
    "Bias can enter the system in any of the three steps above.  The training data set may be biased in that its outcomes may be biased towards particular kinds of instances.  The algorithm that creates the model may be biased in that it may generate models that are weighted towards particular features in the input. The test data set may be biased in that it has expectations on correct answers that may be biased.  These three points in the machine learning process represent points for testing and mitigating bias.  In AI Fairness 360 codebase, we call these points _pre-processing_, _in-processing_, and _post-processing_. \n",
    "\n",
    "## AI Fairness 360\n",
    "We are now ready to utilize AI Fairness 360 (`aif360`) to detect and mitigate bias.  We will use the German credit dataset, splitting it into a training and test dataset.  We will look for bias in the creation of a machine learning model to predict if an applicant should be given credit based on various features from a typical credit application.  The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the privileged and unprivileged groups, respectively.\n",
    "For this first tutorial, we will check for bias in the initial training data, mitigate the bias, and recheck.  More sophisticated machine learning workflows are given in the author tutorials and demo notebooks in the codebase.\n",
    "\n",
    "Here are the steps involved\n",
    "#### Step 1: Write import statements\n",
    "#### Step 2: Set bias detection options, load dataset, and split between train and test\n",
    "#### Step 3: Compute fairness metric on original training dataset\n",
    "#### Step 4: Mitigate bias by transforming the original dataset\n",
    "#### Step 5: Compute fairness metric on transformed training dataset\n",
    "\n",
    "## Step 1 Import Statements\n",
    "As with any python program, the first step will be to import the necessary packages.  Below we import several components from the `aif360` package.  We import the GermanDataset, metrics to check for bias, and classes related to the algorithm we will use to mitigate bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, DatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Load dataset, specifying protected attribute, and split dataset into train and test\n",
    "In Step 2 we load the initial dataset, setting the protected attribute to be age.  We then split the original dataset into training and testing datasets.  Although we will use only  the training dataset in this tutorial, a normal workflow would also use a test dataset for assessing the efficacy (accuracy, fairness, etc.) during the development of a machine learning model.  Finally, we set two variables (to be used in Step 3) for the privileged (1) and unprivileged (0) values for the age attribute.  These are key inputs for detecting and mitigating bias, which will be Step 3 and Step 4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the German Credit Risk dataset?\n",
    "The original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29\n",
    "\n",
    "#### Loading dataset\n",
    "<b>protected_attribute</b> means the attribute on which the bias can occur, basically the attribute you want to test bias for.\n",
    "\n",
    "<b>privileged_classes</b> means a subset of protected attribute values which are considered privileged from a fairness perspective.\n",
    "\n",
    "In the german dataset: Old (age >= 25) are the privileged class and Young (age < 25) are the unprivileged class.\n",
    "\n",
    "Here we have binary membership in a protected group (age) and this is a binary classification problem.\n",
    "\n",
    "Here, age -> sensitive attribute and Old (age >= 25) is the protected group -> historically systematic advantage group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is already encoded as the algorithms need the dataset to have numerical values and not categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = GermanDataset(protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                                          # attribute for \"sex\" which we do not\n",
    "                                                                          # consider in this evaluation\n",
    "                             privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "                             features_to_drop=['personal_status', 'sex']) # ignore sex-related attributes\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original one hot encoded german dataset shape:  (1000, 57)\n",
      "Train dataset shape:  (700, 57)\n",
      "Test dataset shape:  (300, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original one hot encoded german dataset shape: \",dataset_orig.features.shape)\n",
    "print(\"Train dataset shape: \", dataset_orig_train.features.shape)\n",
    "print(\"Test dataset shape: \", dataset_orig_test.features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object dataset_orig is an aif360 dataset, which has some useful methods and attributes taht you can explore:\n",
    "\n",
    "<b>instance_weights: </b> Weighting for each instance. All equal (ones) by default.\n",
    "\n",
    "<b>metadata</b> : returns a dict which contains details about the creation of the dataset.\n",
    "\n",
    "<b>convert_to_dataframe</b> : converts a structured dataset to a pandas dataframe.\n",
    "\n",
    "<b>de_dummy_code = True</b> : converts dummy-coded columns to categories. \n",
    "\n",
    "<b>set_category = True</b> : sets the de-dummy coded features to categorical type.\n",
    "\n",
    "More documentation is available at https://aif360.readthedocs.io/en/latest/modules/datasets.html.\n",
    "\n",
    "For now, we'll just transform it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dict_df = dataset_orig.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1000, 58)\n",
      "Index(['month', 'credit_amount', 'investment_as_income_percentage',\n",
      "       'residence_since', 'age', 'number_of_credits', 'people_liable_for',\n",
      "       'status=A11', 'status=A12', 'status=A13', 'status=A14',\n",
      "       'credit_history=A30', 'credit_history=A31', 'credit_history=A32',\n",
      "       'credit_history=A33', 'credit_history=A34', 'purpose=A40',\n",
      "       'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43',\n",
      "       'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48',\n",
      "       'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63',\n",
      "       'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72',\n",
      "       'employment=A73', 'employment=A74', 'employment=A75',\n",
      "       'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103',\n",
      "       'property=A121', 'property=A122', 'property=A123', 'property=A124',\n",
      "       'installment_plans=A141', 'installment_plans=A142',\n",
      "       'installment_plans=A143', 'housing=A151', 'housing=A152',\n",
      "       'housing=A153', 'skill_level=A171', 'skill_level=A172',\n",
      "       'skill_level=A173', 'skill_level=A174', 'telephone=A191',\n",
      "       'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202',\n",
      "       'credit'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>investment_as_income_percentage</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_credits</th>\n",
       "      <th>people_liable_for</th>\n",
       "      <th>status=A11</th>\n",
       "      <th>status=A12</th>\n",
       "      <th>status=A13</th>\n",
       "      <th>...</th>\n",
       "      <th>housing=A153</th>\n",
       "      <th>skill_level=A171</th>\n",
       "      <th>skill_level=A172</th>\n",
       "      <th>skill_level=A173</th>\n",
       "      <th>skill_level=A174</th>\n",
       "      <th>telephone=A191</th>\n",
       "      <th>telephone=A192</th>\n",
       "      <th>foreign_worker=A201</th>\n",
       "      <th>foreign_worker=A202</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  credit_amount  investment_as_income_percentage  residence_since  \\\n",
       "0    6.0         1169.0                              4.0              4.0   \n",
       "1   48.0         5951.0                              2.0              2.0   \n",
       "2   12.0         2096.0                              2.0              3.0   \n",
       "3   42.0         7882.0                              2.0              4.0   \n",
       "4   24.0         4870.0                              3.0              4.0   \n",
       "\n",
       "   age  number_of_credits  people_liable_for  status=A11  status=A12  \\\n",
       "0  1.0                2.0                1.0         1.0         0.0   \n",
       "1  0.0                1.0                1.0         0.0         1.0   \n",
       "2  1.0                1.0                2.0         0.0         0.0   \n",
       "3  1.0                1.0                2.0         1.0         0.0   \n",
       "4  1.0                2.0                2.0         1.0         0.0   \n",
       "\n",
       "   status=A13  ...  housing=A153  skill_level=A171  skill_level=A172  \\\n",
       "0         0.0  ...           0.0               0.0               0.0   \n",
       "1         0.0  ...           0.0               0.0               0.0   \n",
       "2         0.0  ...           0.0               0.0               1.0   \n",
       "3         0.0  ...           1.0               0.0               0.0   \n",
       "4         0.0  ...           1.0               0.0               0.0   \n",
       "\n",
       "   skill_level=A173  skill_level=A174  telephone=A191  telephone=A192  \\\n",
       "0               1.0               0.0             0.0             1.0   \n",
       "1               1.0               0.0             1.0             0.0   \n",
       "2               0.0               0.0             1.0             0.0   \n",
       "3               1.0               0.0             1.0             0.0   \n",
       "4               1.0               0.0             1.0             0.0   \n",
       "\n",
       "   foreign_worker=A201  foreign_worker=A202  credit  \n",
       "0                  1.0                  0.0     1.0  \n",
       "1                  1.0                  0.0     2.0  \n",
       "2                  1.0                  0.0     1.0  \n",
       "3                  1.0                  0.0     1.0  \n",
       "4                  1.0                  0.0     2.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", df.shape)\n",
    "print(df.columns)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our primary variables of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  {1.0: 'Old', 0.0: 'Young'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Key: \", dataset_orig.metadata['protected_attribute_maps'][1])\n",
    "df['age'].value_counts().plot(kind='bar')\n",
    "plt.xlabel(\"Age (0 = under 25, 1 = over 25)\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  [{1.0: 'Good Credit', 2.0: 'Bad Credit'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Key: \", dataset_orig.metadata['label_maps'])\n",
    "df['credit'].value_counts().plot(kind='bar')\n",
    "plt.xlabel(\"Credit (1 = Good Credit, 2 = Bad Credit)\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to explore the relationship between these two variables. Do credit scores vary with age? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Compute fairness metric on original training dataset\n",
    "Now that we've identified the protected attribute 'age' and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  \n",
    "\n",
    "##### Mean Difference (same as statistical parity)\n",
    "Compare the percentage of favorable results for the privileged and unprivileged groups, subtracting the former percentage from the latter.\n",
    "\n",
    "The ideal value of this metric is 0.\n",
    "\n",
    "A value < 0 indicates less favorable outcomes for the unprivileged groups.  This is implemented in the method called mean_difference on the BinaryLabelDatasetMetric class.  The code below performs this check and displays the output, showing that the difference is -0.169905."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Original training dataset\")\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Disparate Impact\n",
    "Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group. The ideal value of this metric is 1.0.\n",
    "\n",
    "A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact = 0.766430\n"
     ]
    }
   ],
   "source": [
    "print(\"Original training dataset\")\n",
    "print(\"Disparate Impact = %f\" % metric_orig_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainers\n",
    "\n",
    "###### Text Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_expl = MetricTextExplainer(metric_orig_train)\n",
    "json_expl = MetricJSONExplainer(metric_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.1699054740619017\n"
     ]
    }
   ],
   "source": [
    "#print(text_expl.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\n"
     ]
    }
   ],
   "source": [
    "#print(text_expl.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### JSON Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(json_str):\n",
    "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Mean Difference\",\n",
      "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.1699054740619017\",\n",
      "  \"numPositivesUnprivileged\": 63.0,\n",
      "  \"numInstancesUnprivileged\": 113.0,\n",
      "  \"numPositivesPrivileged\": 427.0,\n",
      "  \"numInstancesPrivileged\": 587.0,\n",
      "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#print(format_json(json_expl.mean_difference()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metric\": \"Disparate Impact\",\n",
      "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
      "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
      "  \"numUnprivileged\": 113.0,\n",
      "  \"numPositivePredictionsPrivileged\": 427.0,\n",
      "  \"numPrivileged\": 587.0,\n",
      "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
      "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#print(format_json(json_expl.disparate_impact()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Mitigate bias by transforming the original dataset\n",
    "The previous step showed that the privileged group was getting 17% more positive outcomes in the training dataset.   Since this is not desirable, we are going to try to mitigate this bias in the training dataset.  As stated above, this is called _pre-processing_ mitigation because it happens before the creation of the model.  \n",
    "\n",
    "AI Fairness 360 implements several pre-processing mitigation algorithms.  We will choose the Reweighing algorithm [1], which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package.  This algorithm will transform the dataset to have more equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
    "\n",
    "We then call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (dataset_transf_train).\n",
    "\n",
    "`[1] F. Kamiran and T. Calders,  \"Data Preprocessing Techniques for Classification without Discrimination,\" Knowledge and Information Systems, 2012.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reweighing:</b> Reweighing is a data preprocessing technique that recommends generating weights for the training examples in each (group, label) combination differently to ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training dataset to make the training dataset discrimination free with respect to the sensitive attributes. Instead of reweighing, one could also apply techniques (non-discrimination constraints) such as suppression (remove sensitive attributes) or massaging the dataset — modify the labels (change the labels appropriately to remove discrimination from the training data). However, the reweighing technique is more effective than the other two mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.678     , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.678     , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 1.25555556, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.678     , 1.100625  , 1.100625  , 0.96229508, 1.25555556,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.678     , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.25555556,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.100625  , 1.100625  , 1.25555556,\n",
       "       0.96229508, 0.678     , 1.100625  , 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.678     , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.25555556, 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 1.25555556,\n",
       "       1.100625  , 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.678     , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 1.25555556,\n",
       "       1.25555556, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.25555556, 0.96229508,\n",
       "       1.100625  , 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 0.96229508, 1.25555556, 0.678     ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.25555556, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.678     , 1.100625  ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 1.25555556, 1.100625  ,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.678     ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 1.100625  , 1.25555556, 0.96229508, 1.100625  ,\n",
       "       1.25555556, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 0.96229508, 1.100625  , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.25555556, 0.678     , 0.96229508,\n",
       "       0.96229508, 1.25555556, 0.678     , 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.678     , 1.100625  , 1.100625  , 1.100625  ,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 0.678     , 1.100625  , 1.100625  ,\n",
       "       0.678     , 0.96229508, 1.100625  , 0.96229508, 0.678     ,\n",
       "       0.96229508, 1.25555556, 0.678     , 1.25555556, 0.96229508,\n",
       "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
       "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 0.96229508, 0.96229508, 0.678     , 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.100625  ,\n",
       "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
       "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
       "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
       "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.678     , 1.25555556, 1.25555556, 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
       "       1.100625  , 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
       "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
       "       0.96229508, 1.25555556, 1.25555556, 0.96229508, 0.96229508])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_transf_train.instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_transf_train.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Compute fairness metric on transformed dataset\n",
    "Now that we have a transformed dataset, we can check how effective it was in removing bias by using the same metric we used for the original training dataset in Step 3.  Once again, we use the function mean_difference in the BinaryLabelDatasetMetric class.   We see the mitigation step was very effective, the difference in mean outcomes is now 0.0.  So we went from a 17% advantage for the privileged group to equality in terms of mean outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "print(\"Transformed training dataset\")\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact = 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed training dataset\")\n",
    "print(\"Disparate Impact = %f\" % metric_transf_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Try another algorithm!\n",
    "\n",
    "There are numerous other pre-processing mitigation algorithms implemented in aif360, described at the following link:\n",
    "\n",
    "https://aif360.readthedocs.io/en/latest/modules/preprocessing.html#\n",
    "\n",
    "Take a minute to read about these options, then repeat Steps 4 and 5 above using a different algorithm. How do the fairness metrics compare? What could explain your similar/different results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the pre-processing mitigation algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fairness metrics using your transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The purpose of this tutorial is to give a new user to bias detection and mitigation a gentle introduction to some of the functionality of AI Fairness 360.  A more complete use case would take the next step and see how the transformed dataset impacts the accuracy and fairness of a trained model.  This is implemented in the demo notebook in the examples directory of toolkit, called demo_reweighing_preproc.ipynb.  I highly encourage readers to view that notebook as it is  generalization and extension of this simple tutorial.\n",
    "\n",
    "There are many metrics one can use to detect the presence of bias. AI Fairness 360 provides many of them for your use. Since it is not clear which of these metrics to use, we also provide some guidance. Likewise, there are many different bias mitigation algorithms one can employ, many of which are in AI Fairness 360. Other tutorials will demonstrate the use of some of these metrics and mitigations algorithms.\n",
    "\n",
    "As mentioned earlier, both fairness metrics and mitigation algorithms can be performed at various stages of the machine learning pipeline.  We recommend checking for bias as often as possible, using as many metrics are relevant for the application domain.  We also recommend incorporating bias detection in an automated continouus integration pipeline to ensure bias awareness as a software project evolves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rds_env]",
   "language": "python",
   "name": "conda-env-rds_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
